---
title : 推荐系统-RecommenderSystem
---

## 推荐系统 

自动推荐内容或产品以个性化的方式向适当的用户提供,以增强整体体验。推荐系统在术语上非常强大使用海量的数据,学会理解偏好。

对于PySpark中的“推荐系统”模块 **pyspark.ml.recommendation module**        
[官方文档链接：api/python/pyspark.ml.html#module-pyspark.ml.recommendation](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.recommendation)

### 最重要的：ALS 算法

交替最小平方 (ALS) 矩阵分解:
ALS 尝试将评级矩阵 R 估计为两个较低级别矩阵(X 和 Y,即 X = Yt = R)的乘积。一般方法是迭代。在每次迭代期间,一个因子矩阵保持不变,而另一个因子矩阵使用最小二乘求解。然后,在求解另一个因子矩阵时,新求解的因子矩阵保持不变。
这是 ALS 分解算法的阻塞实现,该算法将两组因子(称为"用户"和"产品")分组到块中,并通过在每个迭代时仅向每个产品块发送每个用户矢量的一个副本来减少通信,并且仅适用于需要该用户功能矢量的产品块。这是通过预先计算一些关于评级矩阵的信息来实现的,以确定每个用户的"外链接"(它将贡献哪些产品块)和每个产品的"链接内"信息(它从每个用户接收到的功能向量中阻止,它将取决于)。这允许我们在每个用户块和产品块之间只发送一组功能矢量,并让产品块查找用户的评级并根据这些消息更新产品。
对于隐式首选项数据,所使用的算法基于"隐式反馈数据集的协作筛选",适用于此处使用的阻塞方法。
从本质上讲,它不是查找评级矩阵 R 的低等级近似值,而是查找首选项矩阵 P 的近似值,其中 P 的元素是 1(如果 r = 0),如果 r = 0,则为 0。然后,评级充当与指示用户首选项的强度相关的"置信"值,而不是对项目给出的明确评级

原理就是给各个指标,判定等加权重,然后将这些训练集输入ALS,包括其他的参数,内部进行矩阵相乘,根据这些权重,给用户对未知,未点击的商品也给一个分数,就是喜好程度. 然后把喜好程度高的商品推荐给用户,假如用户不喜欢,从线上观察效果不好,那这个模型就有问题,需要修改参数,修改权重,或者添加权重,使之达到一个理想的效果!最近项目中用到了这个算法,算是做个总结吧,粗浅的总结,等以后有机会有更深的理解再来填充,修改!

ALS算法输入的参数我们的推荐系统是基于ALS算法中的train方法,我们之前的统计的一些指标都是为了这个推荐系统,把合适的商品推荐给需要的人群,提高用户体验和销售额,和京东淘宝的推荐也是类似的; ALS推荐基于隐语义模型, ALS算法共输入4个参数参数一: 训练集用户对我们这件商品的评分,用户点击了这件商品,我们就给一个评分,然后点击了这个商品的下一步又是多少评分,订单又是多少分,还有访问步长也有加权分,访问时常也有加权分,到最后付款,一共1分.每一步的评分其实就是一个权重.也可以理解为用户对商品合适程度,喜好程度.用户和商品就组成了一个矩阵,只要用户点击了商品,就对这个商品有个评分了,而有的却没有点击,它是空白的,我们要做的就是填充这些空白,在空白处根据之前的权重预测一个评分.然后推荐.假如预测分和真是分不匹配,我们就优化参数,线上观察效果,再优化权重分,参数.训练集是用户，物品，评分.,是一个double类型参数二: 特征值给一个特征值,也是double类型的,可以很多参数,可以很少,这个是模型了,看你的模型设计了,如0.1,然后矩阵与特征相乘,所有的特征值与矩阵相乘的分相加,就得到了一个预测分.假如预测分与实际分不同的话, 那就是特征值给的有问题了,可以修改特征值参数,直到和预测分类似即可.这就是那些算法工程师一直线上看效果,然后调参数了参数三: 迭代参数这个参数是让模型趋近于平稳,也是一个double值,也就是它的标准差越来越平稳,迭代之后会产生一个预测分,((预测分-真实分)的平方+预测分) / n 在发个方,这就是标准差,只要标准差越来越平稳,也就是收敛,就这OK了,.迭代参数就好了参数四: 防过拟合参数这个参数也是一个和double值,过拟合比如给机器看一个红色的苹果,突然给一张青色的苹果让它识别, 它就不认识这是一个苹果了,就是为了满足尽可能复杂的任务,我们给它的一个参数. 不妨参数的话,他就像一个单调函数,无法涵盖所有的点,而我们的目的就是为了涵盖大多数的点,如下图所示
